# Глава 1 (Продължение). Проучване на принципи, практики и технологии

## 1.4. Технологии за контейнеризация: Docker

Преди да се разгледат системите за оркестрация, е необходимо да се дефинира технологичният фундамент, върху който те стъпват – контейнеризацията. Docker е платформата, която революционизира софтуерната индустрия, като демократизира използването на контейнери и ги направи достъпни за масова употреба.

1.4.1. Архитектура и принципи на работа
За разлика от виртуалните машини, които емулират хардуер и изискват пълна инсталация на операционна система върху хипервайзор, Docker използва виртуализация на ниво операционна система [3]. Контейнерите споделят ядрото на хост системата, но работят в изолирани потребителски пространства.

Docker функционира на базата на клиент-сървър архитектура:
- Docker Daemon (dockerd): Това е дълготраен процес, който слуша за API заявки и управлява Docker обектите като имиджи, контейнери, мрежи и томове.
- Docker Client (docker): Основният интерфейс за потребителя. Когато се изпълни команда, клиентът изпраща заявка към демона чрез REST API.
- Docker Registry: Хранилище за Docker имиджи (напр. Docker Hub).

1.4.2. Файлова система и слоеве (Union File System)
Една от най-иновативните характеристики на Docker е използването на слоеста файлова система (UnionFS). Всеки Docker Image се състои от поредица от слоеве, които са само за четене. Когато се стартира контейнер, Docker добавя тънък слой за запис най-отгоре. Този механизъм, известен като Copy-on-Write, позволява изключителна ефективност, тъй като множество контейнери могат да споделят едни и същи базови слоеве.

1.4.3. Мрежова свързаност и съхранение на данни
По подразбиране контейнерите са ефимерни. За персистентно съхранение Docker предоставя Volumes (управлявани области на диска) и Bind Mounts (директно мапване от хост системата). Мрежовата свързаност се осигурява чрез виртуални мостове, където всеки контейнер получава собствен IP адрес, а Docker Daemon управлява правилата за маршрутизация.

> **Предложение за фигура:** Сравнителна схема между VM (Hypervisor + Guest OS) и Docker (Docker Engine + Shared OS Kernel).
> *Фигура 1.4. Сравнение между Виртуални машини и Контейнери [3].*

## 1.5. Системи за оркестрация: Kubernetes (K8s)

Kubernetes е платформа с отворен код за автоматизирано внедряване, скалиране и управление на контейнеризирани приложения [4]. Тя решава проблема с управлението на жизнения цикъл на контейнерите в големи разпределени системи.

1.5.1. Декларативен модел и Цикъл на помирение (Reconciliation Loop)
В основата на Kubernetes лежи декларативният модел. Потребителят описва желаното състояние на системата, а платформата използва непрекъснати контролни цикли (Control Loops), които следват логиката Observe-Diff-Act. Системата постоянно наблюдава текущото състояние и предприема корективни действия, за да го уеднакви с желаното. Това осигурява висока степен на самолечение (self-healing) на приложенията.

1.5.2. Архитектура на клъстера в детайли

Control Plane (Управляващ слой):
- Kube API Server: Централният нервен възел и единствената входна точка за управление. Преминава през етапи на аутентикация, авторизация (RBAC) и Admission Controllers.
- etcd: Разпределена база данни, използваща алгоритъма за консенсус Raft. Тя съхранява цялото състояние на клъстера. Обикновено се разполага на нечетен брой възли за осигуряване на кворум.
- Kube Scheduler: Отговаря за разпределението на натоварването, избирайки най-подходящия възел за всеки нов под на база ресурси и политики.
- Controller Manager: Изпълнява контролните цикли, които регулират състоянието на обектите в клъстера.

Worker Nodes (Работни възли):
- Kubelet: Основният агент на възела, който гарантира, че контейнерите работят според спецификациите и проверява тяхното здраве.
- Kube-proxy: Поддържа мрежовите правила на хоста и позволява комуникацията към услугите.
- Container Runtime: Софтуерът, отговорен за стартирането на контейнерите (напр. containerd).

1.5.3. Мрежов модел и CNI (Container Network Interface)
Kubernetes налага плосък мрежов модел, при който всеки под има уникален IP адрес, достъпен от всеки друг под без NAT. Стандартът CNI позволява използването на различни мрежови решения като Calico, Cilium или облачни интеграции като AWS VPC CNI. За откриване на услуги се използва вграден DNS сървър (CoreDNS), който позволява на приложенията да комуникират чрез логически имена.

1.5.4. Управление на различни типове натоварвания (Workloads)
Kubernetes предлага специализирани обекти:
- Deployments: За приложения без състояние, позволяващи лесно скалиране и обновяване.
- StatefulSets: За приложения със състояние (бази данни), гарантиращи идентичност и персистентност.
- DaemonSets: Осигуряват работата на даден под на всеки възел (логове, мониторинг).
- Jobs и CronJobs: За задачи с краен срок или периодично изпълнение.

> **Предложение за фигура:** Архитектурна схема на K8s клъстер, показваща Control Plane компонентите (API, etcd, Scheduler) и Worker Nodes (Kubelet, Proxy).
> *Фигура 1.5. Архитектура на Kubernetes клъстер [4].*

## 1.6. Пакетно управление с Helm

В контекста на Kubernetes, деплоймънтът на едно съвременно приложение рядко се изчерпва с един единствен контейнер. Обикновено то изисква координацията на множество взаимосвързани обекти. Helm решава този проблема, въвеждайки концепцията за пакетиране на Kubernetes приложения [9].

1.6.1. Архитектура и структура на Helm Chart
Основната единица в Helm е т.нар. Chart (карта). Стандартната структура на един Chart включва:
- Chart.yaml: Метаданни за пакета (име, версия).
- values.yaml: Стойности по подразбиране за конфигурацията.
- templates/: Директория със шаблони (Go templates).

1.6.2. Шаблонизиране и генериране на манифести
Helm използва мощен шаблонизиращ двигател, базиран на Go templates. Потребителят предоставя свои конфигурационни стойности, които презаписват тези във values.yaml, а Helm енджинът генерира финалните YAML манифести.

1.6.3. Управление на релийзи и атомарност
Всяка инсталация на Chart създава нова инстанция, наречена Release. Helm следи състоянието на всеки релийз, позволявайки операции като Upgrade, Rollback и атомарни деплоймънти.

## 1.7. Оперативен модел GitOps и ArgoCD

GitOps представлява еволюция в методологиите за непрекъсната доставка (Continuous Delivery), базирана на идеята, че Git хранилището е "единственият източник на истината" [10].

1.7.1. Четирите принципа на GitOps
За да се класифицира една система като GitOps, тя трябва да отговаря на четири основни принципа: Декларативно описание, Версиониране, Автоматично изтегляне (Pull Model) и Непрекъснато помирение (Continuous Reconciliation) [10].

1.7.2. Архитектура на ArgoCD
ArgoCD е контролер за Kubernetes, който автоматизира синхронизацията между Git хранилището и клъстера.

1.7.3. Мащабиране чрез модела "App of Applications"
Този подход позволява буутстрапване на цял клъстер чрез едно "родителско" приложение, което сочи към дефинициите на други приложения (Child Apps).

> **Предложение за фигура:** Диаграма на GitOps процеса: Git Commit -> ArgoCD Detection -> Reconciliation Loop -> K8s Cluster Update.
> *Фигура 1.6. Работен поток на GitOps с ArgoCD [5].*